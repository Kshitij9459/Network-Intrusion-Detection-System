# Network-Intrusion-Detection-System
Use of deep learning models to create an extra layer of security

The above code is the implementation of the research paper https://www.sciencedirect.com/science/article/abs/pii/S1389128618311216

Intrusion detection is a crucial service in today’s data networks, and the search for new fast and robust al-
gorithms that are capable of detecting and classifying dangerous traffic is essential to deal with changing
threats and increasing detection difficulty. In this work, we present a new intrusion detection algorithm
with an excellent prediction performance. The prediction is based on a classifier which is a simple and
extremely fast neural network. The classifier implements a policy function that is trained with a novel
reinforcement learning model, where the behavior of the environment is adjusted in parallel with the
learning process.

Considering the importance of current security attacks on
modern highly demanding networks, the economic importance of
services running on these networks and the increased demands
on data networks imposed by these services, it is very important
to rely on automatic systems capable of detecting intrusions in a
fast and reliable manner. Such a system is an Intrusion Detection
Systems (IDS) [1] , being its final goal to fast and accurately analyze
network traffic and to predict potential threats.

The above research paper proposes a new model that
integrates a simulated environment, which provides samples of
network traffic and rewards with an agent, which implements the
classifier, and which is trying to predict the correct intrusion label
based on the network samples given by the environment. The
rewards generated by the environment will be positive/negative
depending on the correct/incorrect prediction of the agent. The
algorithm is trained with the objective of maximizing the total
sum of rewards. An important characteristic of this simulated
environment is that it randomly extracts the new samples (states)
from the dataset of pre-recorded samples. This initial strategy
of random extractions provides good results, however the paper authors
designed for the environment a more sophisticated behavior
that is learned during training, acting against the agent’s policy
(adversarial), so better results may be obtained. That is, the en-
vironment behavior is actively trying to reduce the rewards given
to the agent, by increasing the classifier’s incorrect predictions
and forcing it to learn the most difficult cases. The resulting new
algorithm is then called Adversarial Environment using Reinforce-
ment Learning (AE-RL). How the sampling process and reward
function is implemented by the modified environment constitute
the specific nature of the proposed model. AE-RL is particularly
suited to incorporate a supervised problem which make use of a
labeled dataset into a DRL framework.

For more details refer to the paper https://www.sciencedirect.com/science/article/abs/pii/S1389128618311216
